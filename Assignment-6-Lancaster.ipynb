{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment-6-Lancaster.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ZzrgIg0TriYL","colab_type":"code","outputId":"9fda18f6-e769-4fe2-ea3f-de66d6f166b6","executionInfo":{"status":"ok","timestamp":1576190718126,"user_tz":420,"elapsed":3122,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":82}},"source":["import pandas as pd\n","import numpy as np\n","\n","import nltk\n","nltk.download('punkt')\n","# word tokenize\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","#stemmers\n","from nltk.stem.snowball import SnowballStemmer\n","from nltk.stem import PorterStemmer\n","from nltk.stem import LancasterStemmer\n","#lematize\n","from nltk.stem.wordnet import WordNetLemmatizer\n","nltk.download('wordnet')\n","#term vector and tfidf\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","\n","# Import libraries for feature selection - Filter method\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","\n","#traintest split\n","from sklearn.model_selection import train_test_split\n","\n","#Models\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import confusion_matrix,classification_report\n","from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,balanced_accuracy_score\n","from sklearn import metrics\n","\n","pd.set_option('display.max_colwidth', -2)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uZTfYNmFtOf-","colab_type":"code","outputId":"6a237a33-6bc0-4c56-b19a-7407dd123e2c","executionInfo":{"status":"ok","timestamp":1576190872892,"user_tz":420,"elapsed":114953,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":135}},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","#Change current working directory to gdrive\n","%cd /gdrive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n","/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OvhU42QXtUdu","colab_type":"code","outputId":"26615472-89e1-4a16-af23-6e4ea06ef038","executionInfo":{"status":"ok","timestamp":1576190883087,"user_tz":420,"elapsed":1466,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":423}},"source":["#Read files\n","textfile = r'/gdrive/My Drive/CIS 508 Python/Assignment-6/Comments.csv'\n","textData = pd.read_csv(textfile) #creates a dataframe\n","\n","CustInfofile = r'/gdrive/My Drive/CIS 508 Python/Assignment-6/Customers.csv'\n","CustInfoData = pd.read_csv(CustInfofile)  #creates a dataframe\n","\n","print(textData.shape)\n","print(CustInfoData.shape)\n","textData"],"execution_count":3,"outputs":[{"output_type":"stream","text":["(2070, 2)\n","(2070, 17)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Comments</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1309</td>\n","      <td>Does not like the way the phone works. It is to difficult compared to his last phone.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3556</td>\n","      <td>Wanted to know the nearest store location. Wants to buy aditional accessories.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2230</td>\n","      <td>Wants to know how to do text messaging. Referred him to website.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2312</td>\n","      <td>Asked how to disable call waiting. referred him to web site.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3327</td>\n","      <td>Needs help learning how to use the phone. I suggested he go back to the store and have the rep teach him.</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2065</th>\n","      <td>3034</td>\n","      <td>Needed help figuring out his bill. I explained our minute charges.</td>\n","    </tr>\n","    <tr>\n","      <th>2066</th>\n","      <td>271</td>\n","      <td>He lost his phone and called to cancel service. I told him we would suspend until we hear back from him. He will contact us soon.</td>\n","    </tr>\n","    <tr>\n","      <th>2067</th>\n","      <td>783</td>\n","      <td>Lost the directions to phone and wants another manual. I referred him to web site.</td>\n","    </tr>\n","    <tr>\n","      <th>2068</th>\n","      <td>1295</td>\n","      <td>Wants to change address.</td>\n","    </tr>\n","    <tr>\n","      <th>2069</th>\n","      <td>1807</td>\n","      <td>He lost his phone and called to cancel service. I told him we would suspend until we hear back from him. He will contact us soon.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2070 rows × 2 columns</p>\n","</div>"],"text/plain":["        ID                                                                                                                           Comments\n","0     1309  Does not like the way the phone works. It is to difficult compared to his last phone.                                            \n","1     3556  Wanted to know the nearest store location. Wants to buy aditional accessories.                                                   \n","2     2230  Wants to know how to do text messaging. Referred him to website.                                                                 \n","3     2312  Asked how to disable call waiting. referred him to web site.                                                                     \n","4     3327  Needs help learning how to use the phone. I suggested he go back to the store and have the rep teach him.                        \n","...    ...                                                                                                        ...                        \n","2065  3034  Needed help figuring out his bill. I explained our minute charges.                                                               \n","2066  271   He lost his phone and called to cancel service. I told him we would suspend until we hear back from him. He will contact us soon.\n","2067  783   Lost the directions to phone and wants another manual. I referred him to web site.                                               \n","2068  1295  Wants to change address.                                                                                                         \n","2069  1807  He lost his phone and called to cancel service. I told him we would suspend until we hear back from him. He will contact us soon.\n","\n","[2070 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"H-Cmr8-lKGUe","colab_type":"code","outputId":"83c28b9c-eee5-41a4-a413-ec0d8697d902","executionInfo":{"status":"ok","timestamp":1576190885516,"user_tz":420,"elapsed":742,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":245}},"source":["#Extract target column from Customer Info file\n","y_train = CustInfoData[\"TARGET\"]\n","X_train = CustInfoData.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n","                     \n","print(X_train.shape)\n","print(textData.shape)\n","textData.head()\n","print(y_train)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["(2070, 16)\n","(2070, 2)\n","0       Cancelled\n","1       Current  \n","2       Current  \n","3       Current  \n","4       Cancelled\n","          ...    \n","2065    Cancelled\n","2066    Cancelled\n","2067    Cancelled\n","2068    Cancelled\n","2069    Cancelled\n","Name: TARGET, Length: 2070, dtype: object\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A71KiKLt6veD","colab_type":"text"},"source":["# Word Tokenize"]},{"cell_type":"code","metadata":{"id":"dECrlLDRtz1O","colab_type":"code","outputId":"79acba84-4835-4720-d410-db1400348380","executionInfo":{"status":"ok","timestamp":1576190887625,"user_tz":420,"elapsed":921,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":212}},"source":["#tokenise the sentences into words\n","textData['CommentsTokenized'] = textData['Comments'].apply(word_tokenize)\n","print(textData['CommentsTokenized'])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["0       [Does, not, like, the, way, the, phone, works, ., It, is, to, difficult, compared, to, his, last, phone, .]                                                       \n","1       [Wanted, to, know, the, nearest, store, location, ., Wants, to, buy, aditional, accessories, .]                                                                   \n","2       [Wants, to, know, how, to, do, text, messaging, ., Referred, him, to, website, .]                                                                                 \n","3       [Asked, how, to, disable, call, waiting, ., referred, him, to, web, site, .]                                                                                      \n","4       [Needs, help, learning, how, to, use, the, phone, ., I, suggested, he, go, back, to, the, store, and, have, the, rep, teach, him, .]                              \n","                                                                        ...                                                                                               \n","2065    [Needed, help, figuring, out, his, bill, ., I, explained, our, minute, charges, .]                                                                                \n","2066    [He, lost, his, phone, and, called, to, cancel, service, ., I, told, him, we, would, suspend, until, we, hear, back, from, him, ., He, will, contact, us, soon, .]\n","2067    [Lost, the, directions, to, phone, and, wants, another, manual, ., I, referred, him, to, web, site, .]                                                            \n","2068    [Wants, to, change, address, .]                                                                                                                                   \n","2069    [He, lost, his, phone, and, called, to, cancel, service, ., I, told, him, we, would, suspend, until, we, hear, back, from, him, ., He, will, contact, us, soon, .]\n","Name: CommentsTokenized, Length: 2070, dtype: object\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qVlY489d60QT","colab_type":"text"},"source":["# Lancaster Stemming"]},{"cell_type":"code","metadata":{"id":"XurC1OThzdxE","colab_type":"code","outputId":"9aff32f5-3dba-47b7-b208-815489a114cf","executionInfo":{"status":"ok","timestamp":1576190919271,"user_tz":420,"elapsed":1126,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":228}},"source":["pd.options.display.max_rows\n","pd.set_option('display.max_colwidth', -2)\n","#Lancaster stemming\n","# Use English stemmer.\n","lancaster=LancasterStemmer()\n","newTextData=pd.DataFrame()\n","newTextData=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n","newTextData['CommentsTokenizedStemmedLancaster'] = textData['CommentsTokenized'].apply(lambda x: [lancaster.stem(y) for y in x])\n","print('-------------Lancaster Stemming------------------')\n","newTextData['CommentsTokenizedStemmedLancaster']\n","#Join stemmed strings\n","newTextData['CommentsTokenizedStemmedLancaster'] = newTextData['CommentsTokenizedStemmedLancaster'].apply(lambda x: \" \".join(x))\n","newTextData['CommentsTokenizedStemmedLancaster']"],"execution_count":7,"outputs":[{"output_type":"stream","text":["-------------Lancaster Stemming------------------\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0       doe not lik the way the phon work . it is to difficult comp to his last phon .                                              \n","1       want to know the nearest stor loc . want to buy adit access .                                                               \n","2       want to know how to do text mess . refer him to websit .                                                                    \n","3       ask how to dis cal wait . refer him to web sit .                                                                            \n","4       nee help learn how to us the phon . i suggest he go back to the stor and hav the rep teach him .                            \n","                                                      ...                                                                           \n","2065    nee help fig out his bil . i explain our minut charg .                                                                      \n","2066    he lost his phon and cal to cancel serv . i told him we would suspend until we hear back from him . he wil contact us soon .\n","2067    lost the direct to phon and want anoth man . i refer him to web sit .                                                       \n","2068    want to chang address .                                                                                                     \n","2069    he lost his phon and cal to cancel serv . i told him we would suspend until we hear back from him . he wil contact us soon .\n","Name: CommentsTokenizedStemmedLancaster, Length: 2070, dtype: object"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"jDY0AiIcJRoE","colab_type":"text"},"source":["# Creating Vector - Lancaster"]},{"cell_type":"code","metadata":{"id":"OxBdzDtjJMK2","colab_type":"code","outputId":"93f70fc4-64b1-410f-eabb-061c540157cc","executionInfo":{"status":"ok","timestamp":1576190922997,"user_tz":420,"elapsed":526,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":313}},"source":["#Do Bag-Of-Words model - Term - Document Matrix - Lancaster\n","#Learn the vocabulary dictionary and return term-document matrix.\n","#count_vect = CountVectorizer(stop_words=None)\n","count_vect = CountVectorizer(stop_words='english',lowercase=False)\n","count_vect\n","TD_counts = count_vect.fit_transform(newTextData.CommentsTokenizedStemmedLancaster)\n","print(\"Vocabulary \",(count_vect.vocabulary_))\n","print(\"Number of words in vocabulary\",len(count_vect.vocabulary_))\n","print(\"Shape of text vector\",TD_counts.shape)\n","DF_TD_Counts=pd.DataFrame(TD_counts.toarray(), columns= count_vect.get_feature_names())\n","print(DF_TD_Counts)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Vocabulary  {'doe': 96, 'lik': 173, 'way': 341, 'phon': 224, 'work': 356, 'difficult': 92, 'comp': 58, 'want': 339, 'know': 167, 'nearest': 201, 'stor': 283, 'loc': 176, 'buy': 40, 'adit': 9, 'access': 3, 'text': 303, 'mess': 189, 'refer': 243, 'websit': 344, 'ask': 23, 'dis': 95, 'cal': 41, 'wait': 338, 'web': 343, 'sit': 270, 'nee': 202, 'help': 144, 'learn': 171, 'suggest': 289, 'hav': 141, 'rep': 245, 'teach': 298, 'new': 205, 'plan': 226, 'switch': 296, 'soon': 276, 'mor': 196, 'minut': 191, 'addit': 6, 'ory': 213, 'said': 256, 'battery': 27, 'nev': 204, 'wel': 346, 'asap': 22, 'claim': 54, 'charg': 50, 'real': 238, 'result': 248, 'alway': 15, 'dying': 101, 'cur': 79, 'contract': 70, 'batery': 26, 'chang': 49, 'ring': 251, 'ton': 317, 'lost': 180, 'direct': 94, 'anoth': 18, 'man': 186, 'numb': 207, 'becaus': 28, 'mr': 198, 'napeleon': 199, 'leroy': 172, 'expect': 113, 'sign': 266, 'bet': 30, 'techn': 299, 'support': 291, 'pleas': 227, 'tak': 297, 'outbound': 216, 'list': 175, 'rat': 237, 'end': 105, 'year': 361, 'inform': 158, 'famy': 118, 'screening': 260, 'facepl': 116, 'lin': 174, 'week': 345, 'forward': 125, 'custom': 81, 'car': 43, 'hop': 150, 'additon': 7, 'wif': 351, 'wish': 353, 'handset': 137, 'big': 31, 'uncomfort': 327, 'long': 178, 'tim': 312, 'unhappy': 329, 'self': 261, 'serv': 263, 'stuff': 284, 'think': 307, 'al': 14, 'sam': 258, 'bil': 32, 'transfer': 321, 'address': 8, 'cancel': 42, 'told': 316, 'suspend': 295, 'hear': 142, 'wil': 352, 'contact': 68, 'coupl': 73, 'oth': 215, 'feat': 119, 'point': 228, 'say': 259, 'ther': 304, 'ar': 21, 'num': 206, 'mad': 183, 'simply': 268, 'trust': 324, 'problem': 233, 'rel': 244, 'just': 164, 'suck': 288, 'anyth': 19, 'near': 200, 'hous': 152, 'suspect': 294, 'defect': 87, 'day': 84, 'bought': 34, 'receiv': 240, 'hom': 149, 'horr': 151, 'exact': 112, 'drop': 99, 'going': 133, 'fix': 123, 'thi': 306, 'diff': 91, 'cel': 47, 'company': 59, 'sint': 269, 'hat': 140, 'understand': 328, 'gav': 130, 'piec': 225, 'rub': 254, 'tri': 323, 'explain': 115, 'bring': 36, 'wast': 340, '3399': 0, 'fig': 121, 'adress': 10, 'ad': 4, 'provid': 235, 'check': 51, 'vm': 336, 'xvyx': 360, 'pda': 220, 'built': 37, 'wher': 348, 'funct': 127, 'did': 89, 'model': 194, 'fed': 120, 'ing': 159, 'pay': 219, 'som': 273, 'cost': 72, 'credit': 76, 'friend': 126, 'gre': 135, 'wa': 337, 'weak': 342, 'ev': 108, 'replac': 246, 'sim': 267, 'chip': 52, 'wll': 354, 'reent': 242, 'book': 33, 'mak': 185, 'easy': 102, 'info': 157, 'internet': 160, 'complaint': 62, 'maj': 184, 'issu': 162, 'button': 39, 'wer': 347, 'hard': 139, 'happy': 138, 'aft': 13, 'toilet': 315, 'surpr': 293, 'fin': 122, 'adapt': 5, 'perform': 222, 'send': 262, 'slow': 271, 'dec': 86, 'spee': 278, 'cstmr': 78, 'consist': 66, 'consisit': 65, 'good': 134, 'transeff': 319, 'customr': 82, 'dead': 85, 'goat': 132, 'thes': 305, 'pass': 218, 'superv': 290, 'rud': 255, 'upset': 333, 'busy': 38, 'purpos': 236, 'useless': 334, 'cstmer': 77, 'clear': 55, 'bad': 24, 'stat': 280, 'cov': 74, 'los': 179, 'angel': 16, 'york': 363, 'afraid': 12, 'network': 203, 'travel': 322, 'kid': 165, 'cre': 75, 'ticket': 310, 'dont': 98, 'kno': 166, 'someon': 274, 'wors': 357, 'abysm': 2, 'yo': 362, 'forev': 124, 'bas': 25, 'cust': 80, 'omer': 210, 'locatn': 177, 'stol': 282, 'today': 314, 'dur': 100, 'tel': 300, 'policy': 229, 'lctn': 170, 'poss': 231, 'caus': 45, 'brain': 35, 'heard': 143, 'inadequ': 155, 'everywh': 110, 'highway': 146, 'cc': 46, 'turn': 326, 'ot': 214, 'improv': 154, 'fut': 129, '3g': 1, 'metropolit': 190, 'terr': 301, 'fals': 117, 'advert': 11, 'test': 302, 'equip': 107, 'lov': 182, 'lam': 168, 'stil': 281, 'believ': 29, 'stupid': 285, 'worst': 358, 'encount': 104, 'furtherm': 128, 'shitty': 264, 'giv': 131, 'enemy': 106, 'transf': 320, 'cold': 56, 'expir': 114, 'mov': 197, 'city': 53, 'complain': 61, 'market': 187, 'peopl': 221, 'sold': 272, 'person': 223, 'continu': 69, 'rid': 249, 'wrong': 359, 'correct': 71, 'don': 97, 'angry': 17, 'shut': 265, 'unwil': 332, 'die': 90, 'whol': 350, 'includ': 156, 'rol': 253, 'ov': 217, 'competit': 60, 'impl': 153, 'gsm': 136, 'roam': 252, 'sal': 257, 'misl': 192, 'respect': 247, 'wheth': 349, 'right': 250, 'oft': 208, 'try': 325, 'effect': 103, 'dat': 83, 'til': 311, 'hochy': 147, 'momm': 195, 'wold': 355, 'sur': 292, 'mean': 188, 'thought': 309, 'deo': 88, 'poor': 230, 'evrey': 111, 'recpt': 241, 'unrely': 331, 'valu': 335, 'connect': 64, 'subst': 286, 'high': 145, 'comapr': 57, 'opt': 212, 'lot': 181, 'start': 279, 'mistak': 193, 'sometim': 275, 'thos': 308, 'prop': 234, 'const': 67, 'old': 209, 'everytim': 109, 'certain': 48, 'intersect': 161, 'conceiv': 63, 'tow': 318, 'hol': 148, 'unlimit': 330, 'reason': 239, 'anytim': 20, 'subtract': 287, 'speak': 277, 'op': 211, 'digit': 93, 'lat': 169, 'jun': 163, 'prob': 232, 'carry': 44, 'tir': 313}\n","Number of words in vocabulary 364\n","Shape of text vector (2070, 364)\n","      3399  3g  abysm  access  ad  adapt  ...  worst  wrong  xvyx  year  yo  york\n","0     0     0   0      0       0   0      ...  0      0      0     0     0   0   \n","1     0     0   0      1       0   0      ...  0      0      0     0     0   0   \n","2     0     0   0      0       0   0      ...  0      0      0     0     0   0   \n","3     0     0   0      0       0   0      ...  0      0      0     0     0   0   \n","4     0     0   0      0       0   0      ...  0      0      0     0     0   0   \n","...  ..    ..  ..     ..      ..  ..      ... ..     ..     ..    ..    ..  ..   \n","2065  0     0   0      0       0   0      ...  0      0      0     0     0   0   \n","2066  0     0   0      0       0   0      ...  0      0      0     0     0   0   \n","2067  0     0   0      0       0   0      ...  0      0      0     0     0   0   \n","2068  0     0   0      0       0   0      ...  0      0      0     0     0   0   \n","2069  0     0   0      0       0   0      ...  0      0      0     0     0   0   \n","\n","[2070 rows x 364 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5weTCTU1JlBM","colab_type":"text"},"source":["# TF-IDF Matrix "]},{"cell_type":"code","metadata":{"id":"VNyELvuIJZdS","colab_type":"code","outputId":"a92ef40d-42e3-4595-d779-ef31b1ed4c94","executionInfo":{"status":"ok","timestamp":1576192615516,"user_tz":420,"elapsed":498,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":261}},"source":["#Compute TF-IDF Matrix\n","tfidf_transformer = TfidfTransformer()\n","X_train_tfidf = tfidf_transformer.fit_transform(DF_TD_Counts)\n","print(X_train_tfidf.shape)\n","DF_TF_IDF=pd.DataFrame(X_train_tfidf.toarray(),columns= DF_TD_Counts.columns)\n","print(DF_TF_IDF)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["(2070, 364)\n","      3399   3g  abysm    access   ad  ...  wrong  xvyx  year   yo  york\n","0     0.0   0.0  0.0    0.000000  0.0  ...  0.0    0.0   0.0   0.0  0.0 \n","1     0.0   0.0  0.0    0.275669  0.0  ...  0.0    0.0   0.0   0.0  0.0 \n","2     0.0   0.0  0.0    0.000000  0.0  ...  0.0    0.0   0.0   0.0  0.0 \n","3     0.0   0.0  0.0    0.000000  0.0  ...  0.0    0.0   0.0   0.0  0.0 \n","4     0.0   0.0  0.0    0.000000  0.0  ...  0.0    0.0   0.0   0.0  0.0 \n","...   ...   ...  ...         ...  ...  ...  ...    ...   ...   ...  ... \n","2065  0.0   0.0  0.0    0.000000  0.0  ...  0.0    0.0   0.0   0.0  0.0 \n","2066  0.0   0.0  0.0    0.000000  0.0  ...  0.0    0.0   0.0   0.0  0.0 \n","2067  0.0   0.0  0.0    0.000000  0.0  ...  0.0    0.0   0.0   0.0  0.0 \n","2068  0.0   0.0  0.0    0.000000  0.0  ...  0.0    0.0   0.0   0.0  0.0 \n","2069  0.0   0.0  0.0    0.000000  0.0  ...  0.0    0.0   0.0   0.0  0.0 \n","\n","[2070 rows x 364 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g7bmx1bMKOYe","colab_type":"text"},"source":["# Feature Selection - Filter "]},{"cell_type":"code","metadata":{"id":"uqSlHN63Jo9-","colab_type":"code","outputId":"6656f91f-dc6d-40fa-c3ee-3a51f674afca","executionInfo":{"status":"ok","timestamp":1576192619337,"user_tz":420,"elapsed":1107,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":765}},"source":["#Feature selection\n","selector = SelectKBest(score_func=chi2, k=30)\n","selector_fit = selector.fit(DF_TF_IDF,y_train)\n","#get scores along with features\n","names = DF_TF_IDF.columns.values[selector.get_support()]\n","scores = selector.scores_[selector.get_support()]\n","names_scores = list(zip(names, scores))\n","ns_df = pd.DataFrame(data = names_scores, columns= ['Feat_names','F_Scores'])\n","ns_df_sorted = ns_df.sort_values(['F_Scores','Feat_names'], ascending = [False, True])\n","print(ns_df_sorted)\n","\n","\n","new_DF_TF_IDF = selector.fit_transform(DF_TF_IDF,y_train)\n","print(\"Shape of TF-IDF after feature selection\", new_DF_TF_IDF.shape)\n","\n","DF_TF_IDF_SelectedFeatures= pd.DataFrame(new_DF_TF_IDF, columns = list(DF_TF_IDF.columns[selector.get_support(indices=True)]) )\n","print(DF_TF_IDF_SelectedFeatures)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["   Feat_names  F_Scores\n","26  transeff   3.570832\n","2   alway      3.345592\n","24  screening  2.955150\n","18  ot         2.567782\n","27  turn       2.567782\n","4   continu    2.439831\n","9   fig        2.193511\n","7   explain    1.995882\n","13  market     1.790824\n","19  peopl      1.790824\n","23  rid        1.790824\n","25  sold       1.790824\n","28  unlimit    1.707520\n","8   famy       1.631145\n","10  hochy      1.556822\n","15  momm       1.556822\n","14  minut      1.493673\n","5   cur        1.447126\n","6   dying      1.447126\n","22  result     1.447126\n","1   adress     1.446067\n","29  weak       1.362714\n","21  rel        1.353019\n","3   chang      1.289874\n","0   address    1.276869\n","20  plan       1.262413\n","11  internet   1.261777\n","12  man        1.203869\n","16  mor        1.157278\n","17  num        1.127669\n","Shape of TF-IDF after feature selection (2070, 30)\n","       address  adress  alway     chang  ...  transeff  turn  unlimit  weak\n","0     0.000000  0.0     0.0    0.000000  ...  0.0       0.0   0.0      0.0 \n","1     0.000000  0.0     0.0    0.000000  ...  0.0       0.0   0.0      0.0 \n","2     0.000000  0.0     0.0    0.000000  ...  0.0       0.0   0.0      0.0 \n","3     0.000000  0.0     0.0    0.000000  ...  0.0       0.0   0.0      0.0 \n","4     0.000000  0.0     0.0    0.000000  ...  0.0       0.0   0.0      0.0 \n","...        ...  ...     ...         ...  ...  ...       ...   ...      ... \n","2065  0.000000  0.0     0.0    0.000000  ...  0.0       0.0   0.0      0.0 \n","2066  0.000000  0.0     0.0    0.000000  ...  0.0       0.0   0.0      0.0 \n","2067  0.000000  0.0     0.0    0.000000  ...  0.0       0.0   0.0      0.0 \n","2068  0.772949  0.0     0.0    0.545354  ...  0.0       0.0   0.0      0.0 \n","2069  0.000000  0.0     0.0    0.000000  ...  0.0       0.0   0.0      0.0 \n","\n","[2070 rows x 30 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eQP8cliaKpgw","colab_type":"code","outputId":"a88de76e-5100-446f-d540-13a0f2e7be2b","executionInfo":{"status":"ok","timestamp":1576192625684,"user_tz":420,"elapsed":522,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":66}},"source":["#split data into training and test\n","#split the entire training data in training and test data\n","X_Train, X_Test, Y_Train, Y_Test = train_test_split( DF_TF_IDF_SelectedFeatures, y_train, test_size=0.20, random_state=42)\n","print(\"Initial shape for entire data:\",DF_TF_IDF_SelectedFeatures.shape)\n","print(\"Shape of new training data:\", X_Train.shape)\n","print(\"Shape of new test split data:\", X_Test.shape)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Initial shape for entire data: (2070, 30)\n","Shape of new training data: (1656, 30)\n","Shape of new test split data: (414, 30)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-lQw4QrlK4EO","colab_type":"text"},"source":["# Classification model on only comments - Random Forest - Filter"]},{"cell_type":"code","metadata":{"id":"to-WwTSdK2q-","colab_type":"code","outputId":"59aaae59-fa5e-466f-813e-66dfc1945a1f","executionInfo":{"status":"ok","timestamp":1576192629101,"user_tz":420,"elapsed":1612,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":423}},"source":["#Construct a Random Forest Classifier on text data\n","rfc=RandomForestClassifier()\n","rfc.fit(X_Train,Y_Train)\n","\n","#Prediction on training data\n","pred_rf=pd.DataFrame(rfc.predict(X_Train),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Training Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on training data using Random Forest:\",accuracy_score(Y_Train,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on training data using Random Forest\\n\", confusion_matrix(Y_Train,pred_rf[\"Prediction\"]))\n","\n","# prediction on test data\n","pred_rf=pd.DataFrame(rfc.predict(X_Test),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Test Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on test data using Random Forest:\",accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Balanced Accuracy Score on test data using Random Forest:\",balanced_accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on test data using Random Forest\\n\", confusion_matrix(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Classification report on test data using Random Forest\\n\", classification_report(Y_Test,pred_rf[\"Prediction\"]))\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["----------------------------Random Forest: Training Data------------------------------------------------\n","\n","Accuracy Score on training data using Random Forest: 0.6292270531400966\n","Confusion Matrix on training data using Random Forest\n"," [[ 60 587]\n"," [ 27 982]]\n","----------------------------Random Forest: Test Data------------------------------------------------\n","\n","Accuracy Score on test data using Random Forest: 0.6280193236714976\n","Balanced Accuracy Score on test data using Random Forest: 0.520706832883095\n","Confusion Matrix on test data using Random Forest\n"," [[ 12 145]\n"," [  9 248]]\n","Classification report on test data using Random Forest\n","               precision    recall  f1-score   support\n","\n","   Cancelled       0.57      0.08      0.13       157\n","     Current       0.63      0.96      0.76       257\n","\n","    accuracy                           0.63       414\n","   macro avg       0.60      0.52      0.45       414\n","weighted avg       0.61      0.63      0.52       414\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"6o0Izqz5LZC6","colab_type":"text"},"source":["#customer data "]},{"cell_type":"code","metadata":{"id":"wrFT9ohILWj4","colab_type":"code","outputId":"06e4ebd0-62f0-4c0c-9114-ab3efcd186a2","executionInfo":{"status":"ok","timestamp":1576192632853,"user_tz":420,"elapsed":880,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":147}},"source":["CustInfoData = CustInfoData.drop(columns=[\"TARGET\"])\n","#Do one Hot encoding for categorical features\n","X_cat = [\"Sex\",\"Status\",\"Car_Owner\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\"]\n","#X_cat = CustInfoData.select_dtypes(include=['object'])\n","customer_one_hot = pd.get_dummies(CustInfoData,columns=X_cat)\n","\n","customer_one_hot = pd.DataFrame(customer_one_hot)\n","print(customer_one_hot.head())"],"execution_count":13,"outputs":[{"output_type":"stream","text":["   ID  ...  LongDistanceBilltype_Standard\n","0  1   ...  0                            \n","1  6   ...  1                            \n","2  8   ...  1                            \n","3  11  ...  1                            \n","4  14  ...  0                            \n","\n","[5 rows x 24 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lNBqoN4XL3lx","colab_type":"text"},"source":["# Classification model on comments + customer data - Random Forest - Filter"]},{"cell_type":"code","metadata":{"id":"23asu6JWL8hA","colab_type":"code","outputId":"949d5071-49c5-4f2b-8e1f-9fd31b4f7a98","executionInfo":{"status":"ok","timestamp":1576192640952,"user_tz":420,"elapsed":849,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":261}},"source":["#Merge files comments and customer data\n","combined=pd.concat([customer_one_hot, DF_TF_IDF_SelectedFeatures], axis=1)\n","print(combined.shape)\n","print(combined)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["(2070, 54)\n","        ID  Children  Est_Income   Usage  ...  transeff  turn  unlimit  weak\n","0     1     1         38000.00    229.64  ...  0.0       0.0   0.0      0.0 \n","1     6     2         29616.00    75.29   ...  0.0       0.0   0.0      0.0 \n","2     8     0         19732.80    47.25   ...  0.0       0.0   0.0      0.0 \n","3     11    2         96.33       59.01   ...  0.0       0.0   0.0      0.0 \n","4     14    2         52004.80    28.14   ...  0.0       0.0   0.0      0.0 \n","...   ..   ..              ...      ...   ...  ...       ...   ...      ... \n","2065  3821  0         78851.30    29.04   ...  0.0       0.0   0.0      0.0 \n","2066  3822  1         17540.70    36.20   ...  0.0       0.0   0.0      0.0 \n","2067  3823  0         83891.90    74.40   ...  0.0       0.0   0.0      0.0 \n","2068  3824  2         28220.80    38.95   ...  0.0       0.0   0.0      0.0 \n","2069  3825  0         28589.10    100.28  ...  0.0       0.0   0.0      0.0 \n","\n","[2070 rows x 54 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_EdxKKPaMNqV","colab_type":"code","outputId":"e7584820-70e4-45df-af1e-3b2df9819339","executionInfo":{"status":"ok","timestamp":1576192643302,"user_tz":420,"elapsed":1025,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":66}},"source":["#split data into training and test\n","#split the entire training data in training and test data\n","X_Train, X_Test, Y_Train, Y_Test = train_test_split( combined, y_train, test_size=0.20, random_state=42)\n","print(\"Initial shape for entire data:\",DF_TF_IDF_SelectedFeatures.shape)\n","print(\"Shape of new training data:\", X_Train.shape)\n","print(\"Shape of new test split data:\", X_Test.shape)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Initial shape for entire data: (2070, 30)\n","Shape of new training data: (1656, 54)\n","Shape of new test split data: (414, 54)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X_gf4Xm2MZjs","colab_type":"code","outputId":"fdecca4a-89cc-4928-cb50-cb83ed74de57","executionInfo":{"status":"ok","timestamp":1576192645388,"user_tz":420,"elapsed":942,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":423}},"source":["#Construct a Random Forest Classifier on combined data\n","rfc=RandomForestClassifier()\n","rfc.fit(X_Train,Y_Train)\n","\n","#Prediction on training data\n","pred_rf=pd.DataFrame(rfc.predict(X_Train),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Training Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on training data using Random Forest:\",accuracy_score(Y_Train,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on training data using Random Forest\\n\", confusion_matrix(Y_Train,pred_rf[\"Prediction\"]))\n","\n","# prediction on test data\n","pred_rf=pd.DataFrame(rfc.predict(X_Test),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Test Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on test data using Random Forest:\",accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Balanced Accuracy Score on test data using Random Forest:\",balanced_accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on test data using Random Forest\\n\", confusion_matrix(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Classification report on test data using Random Forest\\n\", classification_report(Y_Test,pred_rf[\"Prediction\"]))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["----------------------------Random Forest: Training Data------------------------------------------------\n","\n","Accuracy Score on training data using Random Forest: 0.9909420289855072\n","Confusion Matrix on training data using Random Forest\n"," [[ 641    6]\n"," [   9 1000]]\n","----------------------------Random Forest: Test Data------------------------------------------------\n","\n","Accuracy Score on test data using Random Forest: 0.8599033816425121\n","Balanced Accuracy Score on test data using Random Forest: 0.8499838905549084\n","Confusion Matrix on test data using Random Forest\n"," [[127  30]\n"," [ 28 229]]\n","Classification report on test data using Random Forest\n","               precision    recall  f1-score   support\n","\n","   Cancelled       0.82      0.81      0.81       157\n","     Current       0.88      0.89      0.89       257\n","\n","    accuracy                           0.86       414\n","   macro avg       0.85      0.85      0.85       414\n","weighted avg       0.86      0.86      0.86       414\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"mprsVNwgMmGE","colab_type":"text"},"source":["# Feature selection - Wrapper method "]},{"cell_type":"code","metadata":{"id":"VVr9XX-ZMlOr","colab_type":"code","outputId":"29425c6b-5924-4ae5-eb1f-e2afbea3de0a","executionInfo":{"status":"ok","timestamp":1576193648109,"user_tz":420,"elapsed":196432,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n","#Construct a Random Forest Classifier on text data\n","rfc=RandomForestClassifier()\n","\n","sfs1 = SFS(rfc, \n","           k_features=20, \n","           forward=True, \n","           floating=False, \n","           verbose=2,\n","           scoring='accuracy',\n","           cv=0)\n","\n","sfs1 = sfs1.fit(DF_TF_IDF,y_train, custom_feature_names= DF_TF_IDF.columns)\n","print(\"Top 20 feature\", sfs1.k_feature_names_)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 364 out of 364 | elapsed:    7.7s finished\n","\n","[2019-12-12 23:30:59] Features: 1/20 -- score: 0.6231884057971014[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 363 out of 363 | elapsed:    8.7s finished\n","\n","[2019-12-12 23:31:08] Features: 2/20 -- score: 0.6285024154589371[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 362 out of 362 | elapsed:    9.1s finished\n","\n","[2019-12-12 23:31:17] Features: 3/20 -- score: 0.6323671497584541[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 361 out of 361 | elapsed:    9.4s finished\n","\n","[2019-12-12 23:31:26] Features: 4/20 -- score: 0.633816425120773[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:    9.5s finished\n","\n","[2019-12-12 23:31:36] Features: 5/20 -- score: 0.6342995169082125[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 359 out of 359 | elapsed:    9.5s finished\n","\n","[2019-12-12 23:31:45] Features: 6/20 -- score: 0.6347826086956522[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 358 out of 358 | elapsed:    9.6s finished\n","\n","[2019-12-12 23:31:55] Features: 7/20 -- score: 0.6347826086956522[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 357 out of 357 | elapsed:    9.7s finished\n","\n","[2019-12-12 23:32:05] Features: 8/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 356 out of 356 | elapsed:    9.9s finished\n","\n","[2019-12-12 23:32:14] Features: 9/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 355 out of 355 | elapsed:    9.9s finished\n","\n","[2019-12-12 23:32:24] Features: 10/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 354 out of 354 | elapsed:   10.0s finished\n","\n","[2019-12-12 23:32:34] Features: 11/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 353 out of 353 | elapsed:   10.0s finished\n","\n","[2019-12-12 23:32:44] Features: 12/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 352 out of 352 | elapsed:   10.0s finished\n","\n","[2019-12-12 23:32:54] Features: 13/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 351 out of 351 | elapsed:   10.1s finished\n","\n","[2019-12-12 23:33:05] Features: 14/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 350 out of 350 | elapsed:   10.0s finished\n","\n","[2019-12-12 23:33:15] Features: 15/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 349 out of 349 | elapsed:   10.3s finished\n","\n","[2019-12-12 23:33:25] Features: 16/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 348 out of 348 | elapsed:   10.4s finished\n","\n","[2019-12-12 23:33:35] Features: 17/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 347 out of 347 | elapsed:   10.4s finished\n","\n","[2019-12-12 23:33:46] Features: 18/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 346 out of 346 | elapsed:   10.4s finished\n","\n","[2019-12-12 23:33:56] Features: 19/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["Top 20 feature ('3399', 'abysm', 'access', 'ad', 'adapt', 'addit', 'additon', 'address', 'adit', 'adress', 'advert', 'alway', 'anoth', 'ar', 'battery', 'hav', 'momm', 'phon', 'support', 'want')\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done 345 out of 345 | elapsed:   10.5s finished\n","\n","[2019-12-12 23:34:07] Features: 20/20 -- score: 0.6352657004830918"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"C55JGKvjbTYo","colab_type":"code","outputId":"b8a5cd47-7534-45dc-f545-ef8df81c47a8","executionInfo":{"status":"ok","timestamp":1576193648114,"user_tz":420,"elapsed":194590,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":297}},"source":["#top 20 features after Forward\n","print(\"Top 20 feature\", sfs1.k_feature_names_)\n","\n","DF_TF_IDF_SelectedFeatures = DF_TF_IDF.loc[:, DF_TF_IDF.columns.isin(list(sfs1.k_feature_names_))]\n","print(\"Shape of TF-IDF after feature selection\", DF_TF_IDF_SelectedFeatures.shape)\n","print(DF_TF_IDF_SelectedFeatures)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Top 20 feature ('3399', 'abysm', 'access', 'ad', 'adapt', 'addit', 'additon', 'address', 'adit', 'adress', 'advert', 'alway', 'anoth', 'ar', 'battery', 'hav', 'momm', 'phon', 'support', 'want')\n","Shape of TF-IDF after feature selection (2070, 20)\n","      3399  abysm    access   ad  ...  momm      phon  support      want\n","0     0.0   0.0    0.000000  0.0  ...  0.0   0.311374  0.0      0.000000\n","1     0.0   0.0    0.275669  0.0  ...  0.0   0.000000  0.0      0.312446\n","2     0.0   0.0    0.000000  0.0  ...  0.0   0.000000  0.0      0.195324\n","3     0.0   0.0    0.000000  0.0  ...  0.0   0.000000  0.0      0.000000\n","4     0.0   0.0    0.000000  0.0  ...  0.0   0.241722  0.0      0.000000\n","...   ...   ...         ...  ...  ...  ...        ...  ...           ...\n","2065  0.0   0.0    0.000000  0.0  ...  0.0   0.000000  0.0      0.000000\n","2066  0.0   0.0    0.000000  0.0  ...  0.0   0.167537  0.0      0.000000\n","2067  0.0   0.0    0.000000  0.0  ...  0.0   0.188306  0.0      0.153017\n","2068  0.0   0.0    0.000000  0.0  ...  0.0   0.000000  0.0      0.324251\n","2069  0.0   0.0    0.000000  0.0  ...  0.0   0.167537  0.0      0.000000\n","\n","[2070 rows x 20 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vf39k9h9qFDv","colab_type":"code","outputId":"cadb457a-b68d-41e8-bec5-acb3cdf67da8","executionInfo":{"status":"ok","timestamp":1576193649025,"user_tz":420,"elapsed":902,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":66}},"source":["#split data into training and test\n","#split the entire training data in training and test data\n","X_Train, X_Test, Y_Train, Y_Test = train_test_split( DF_TF_IDF_SelectedFeatures, y_train, test_size=0.20, random_state=42)\n","print(\"Initial shape for entire data:\",DF_TF_IDF_SelectedFeatures.shape)\n","print(\"Shape of new training data:\", X_Train.shape)\n","print(\"Shape of new test split data:\", X_Test.shape)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Initial shape for entire data: (2070, 20)\n","Shape of new training data: (1656, 20)\n","Shape of new test split data: (414, 20)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xf3YiRRaq66H","colab_type":"text"},"source":["# Classification on comments - Wrapper method"]},{"cell_type":"code","metadata":{"id":"KyZbFD2_jml7","colab_type":"code","outputId":"291c297f-7818-4539-d43d-82eac8938164","executionInfo":{"status":"ok","timestamp":1576193649026,"user_tz":420,"elapsed":892,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":423}},"source":["#Construct a Random Forest Classifier on text data\n","rfc=RandomForestClassifier()\n","rfc.fit(X_Train,Y_Train)\n","\n","#Prediction on training data\n","pred_rf=pd.DataFrame(rfc.predict(X_Train),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Training Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on training data using Random Forest:\",accuracy_score(Y_Train,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on training data using Random Forest\\n\", confusion_matrix(Y_Train,pred_rf[\"Prediction\"]))\n","\n","# prediction on test data\n","pred_rf=pd.DataFrame(rfc.predict(X_Test),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Test Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on test data using Random Forest:\",accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Balanced Accuracy Score on test data using Random Forest:\",balanced_accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on test data using Random Forest\\n\", confusion_matrix(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Classification report on test data using Random Forest\\n\", classification_report(Y_Test,pred_rf[\"Prediction\"]))"],"execution_count":35,"outputs":[{"output_type":"stream","text":["----------------------------Random Forest: Training Data------------------------------------------------\n","\n","Accuracy Score on training data using Random Forest: 0.6358695652173914\n","Confusion Matrix on training data using Random Forest\n"," [[ 84 563]\n"," [ 40 969]]\n","----------------------------Random Forest: Test Data------------------------------------------------\n","\n","Accuracy Score on test data using Random Forest: 0.6135265700483091\n","Balanced Accuracy Score on test data using Random Forest: 0.5127512453840244\n","Confusion Matrix on test data using Random Forest\n"," [[ 15 142]\n"," [ 18 239]]\n","Classification report on test data using Random Forest\n","               precision    recall  f1-score   support\n","\n","   Cancelled       0.45      0.10      0.16       157\n","     Current       0.63      0.93      0.75       257\n","\n","    accuracy                           0.61       414\n","   macro avg       0.54      0.51      0.45       414\n","weighted avg       0.56      0.61      0.52       414\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Y4SZS-MtrVJm","colab_type":"text"},"source":["# Classification on customers + comments - Wrapper method"]},{"cell_type":"code","metadata":{"id":"zOKJ_1jPrKnq","colab_type":"code","outputId":"b50cfe27-d229-437c-c67a-35518c83c97b","executionInfo":{"status":"ok","timestamp":1576193168644,"user_tz":420,"elapsed":964,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":261}},"source":["#Merge files comments and customer data\n","combined=pd.concat([customer_one_hot, DF_TF_IDF_SelectedFeatures], axis=1)\n","print(combined.shape)\n","print(combined)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["(2070, 44)\n","        ID  Children  Est_Income   Usage  ...  expect  momm  sign      want\n","0     1     1         38000.00    229.64  ...  0.0     0.0   0.0   0.000000\n","1     6     2         29616.00    75.29   ...  0.0     0.0   0.0   0.312446\n","2     8     0         19732.80    47.25   ...  0.0     0.0   0.0   0.195324\n","3     11    2         96.33       59.01   ...  0.0     0.0   0.0   0.000000\n","4     14    2         52004.80    28.14   ...  0.0     0.0   0.0   0.000000\n","...   ..   ..              ...      ...   ...  ...     ...   ...        ...\n","2065  3821  0         78851.30    29.04   ...  0.0     0.0   0.0   0.000000\n","2066  3822  1         17540.70    36.20   ...  0.0     0.0   0.0   0.000000\n","2067  3823  0         83891.90    74.40   ...  0.0     0.0   0.0   0.153017\n","2068  3824  2         28220.80    38.95   ...  0.0     0.0   0.0   0.324251\n","2069  3825  0         28589.10    100.28  ...  0.0     0.0   0.0   0.000000\n","\n","[2070 rows x 44 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ABNqBUMrrxdn","colab_type":"code","outputId":"2c04a645-2caf-4406-8c75-1f6517b74686","executionInfo":{"status":"ok","timestamp":1576193170915,"user_tz":420,"elapsed":928,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":66}},"source":["#split data into training and test\n","#split the entire training data in training and test data\n","X_Train, X_Test, Y_Train, Y_Test = train_test_split( combined, y_train, test_size=0.20, random_state=42)\n","print(\"Initial shape for entire data:\",DF_TF_IDF_SelectedFeatures.shape)\n","print(\"Shape of new training data:\", X_Train.shape)\n","print(\"Shape of new test split data:\", X_Test.shape)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Initial shape for entire data: (2070, 20)\n","Shape of new training data: (1656, 44)\n","Shape of new test split data: (414, 44)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RdJwKIYWryF9","colab_type":"code","outputId":"39512e14-20a0-4be5-c102-4fa669130c37","executionInfo":{"status":"ok","timestamp":1576193172207,"user_tz":420,"elapsed":953,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":423}},"source":["#Construct a Random Forest Classifier on combined data\n","rfc=RandomForestClassifier()\n","rfc.fit(X_Train,Y_Train)\n","\n","#Prediction on training data\n","pred_rf=pd.DataFrame(rfc.predict(X_Train),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Training Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on training data using Random Forest:\",accuracy_score(Y_Train,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on training data using Random Forest\\n\", confusion_matrix(Y_Train,pred_rf[\"Prediction\"]))\n","\n","# prediction on test data\n","pred_rf=pd.DataFrame(rfc.predict(X_Test),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Test Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on test data using Random Forest:\",accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Balanced Accuracy Score on test data using Random Forest:\",balanced_accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on test data using Random Forest\\n\", confusion_matrix(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Classification report on test data using Random Forest\\n\", classification_report(Y_Test,pred_rf[\"Prediction\"]))\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["----------------------------Random Forest: Training Data------------------------------------------------\n","\n","Accuracy Score on training data using Random Forest: 0.9915458937198067\n","Confusion Matrix on training data using Random Forest\n"," [[644   3]\n"," [ 11 998]]\n","----------------------------Random Forest: Test Data------------------------------------------------\n","\n","Accuracy Score on test data using Random Forest: 0.8526570048309179\n","Balanced Accuracy Score on test data using Random Forest: 0.8478648789313242\n","Confusion Matrix on test data using Random Forest\n"," [[130  27]\n"," [ 34 223]]\n","Classification report on test data using Random Forest\n","               precision    recall  f1-score   support\n","\n","   Cancelled       0.79      0.83      0.81       157\n","     Current       0.89      0.87      0.88       257\n","\n","    accuracy                           0.85       414\n","   macro avg       0.84      0.85      0.84       414\n","weighted avg       0.85      0.85      0.85       414\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"],"name":"stderr"}]}]}