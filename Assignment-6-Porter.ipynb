{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment-6-Porter.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ZzrgIg0TriYL","colab_type":"code","outputId":"72d35511-bba9-45cd-f685-ddaef374d8ff","executionInfo":{"status":"ok","timestamp":1576030063062,"user_tz":420,"elapsed":3135,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":82}},"source":["import pandas as pd\n","import numpy as np\n","\n","import nltk\n","nltk.download('punkt')\n","# word tokenize\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","#stemmers\n","from nltk.stem.snowball import SnowballStemmer\n","from nltk.stem import PorterStemmer\n","from nltk.stem import LancasterStemmer\n","#lematize\n","from nltk.stem.wordnet import WordNetLemmatizer\n","nltk.download('wordnet')\n","#term vector and tfidf\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","\n","# Import libraries for feature selection - Filter method\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","\n","#traintest split\n","from sklearn.model_selection import train_test_split\n","\n","#Models\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import confusion_matrix,classification_report\n","from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,balanced_accuracy_score\n","from sklearn import metrics\n","\n","pd.set_option('display.max_colwidth', -2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uZTfYNmFtOf-","colab_type":"code","outputId":"04354a58-d98c-4dfc-e7e8-c9fa6638a909","executionInfo":{"status":"ok","timestamp":1576030083917,"user_tz":420,"elapsed":19114,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":135}},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","#Change current working directory to gdrive\n","%cd /gdrive"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n","/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OvhU42QXtUdu","colab_type":"code","outputId":"82b874c7-11dd-4c6d-80de-aa5377088cea","executionInfo":{"status":"ok","timestamp":1576030085118,"user_tz":420,"elapsed":5017,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":423}},"source":["#Read files\n","textfile = r'/gdrive/My Drive/CIS 508 Python/Assignment-6/Comments.csv'\n","textData = pd.read_csv(textfile) #creates a dataframe\n","\n","CustInfofile = r'/gdrive/My Drive/CIS 508 Python/Assignment-6/Customers.csv'\n","CustInfoData = pd.read_csv(CustInfofile)  #creates a dataframe\n","\n","print(textData.shape)\n","print(CustInfoData.shape)\n","textData"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2070, 2)\n","(2070, 17)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Comments</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1309</td>\n","      <td>Does not like the way the phone works. It is to difficult compared to his last phone.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3556</td>\n","      <td>Wanted to know the nearest store location. Wants to buy aditional accessories.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2230</td>\n","      <td>Wants to know how to do text messaging. Referred him to website.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2312</td>\n","      <td>Asked how to disable call waiting. referred him to web site.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3327</td>\n","      <td>Needs help learning how to use the phone. I suggested he go back to the store and have the rep teach him.</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2065</th>\n","      <td>3034</td>\n","      <td>Needed help figuring out his bill. I explained our minute charges.</td>\n","    </tr>\n","    <tr>\n","      <th>2066</th>\n","      <td>271</td>\n","      <td>He lost his phone and called to cancel service. I told him we would suspend until we hear back from him. He will contact us soon.</td>\n","    </tr>\n","    <tr>\n","      <th>2067</th>\n","      <td>783</td>\n","      <td>Lost the directions to phone and wants another manual. I referred him to web site.</td>\n","    </tr>\n","    <tr>\n","      <th>2068</th>\n","      <td>1295</td>\n","      <td>Wants to change address.</td>\n","    </tr>\n","    <tr>\n","      <th>2069</th>\n","      <td>1807</td>\n","      <td>He lost his phone and called to cancel service. I told him we would suspend until we hear back from him. He will contact us soon.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2070 rows × 2 columns</p>\n","</div>"],"text/plain":["        ID                                                                                                                           Comments\n","0     1309  Does not like the way the phone works. It is to difficult compared to his last phone.                                            \n","1     3556  Wanted to know the nearest store location. Wants to buy aditional accessories.                                                   \n","2     2230  Wants to know how to do text messaging. Referred him to website.                                                                 \n","3     2312  Asked how to disable call waiting. referred him to web site.                                                                     \n","4     3327  Needs help learning how to use the phone. I suggested he go back to the store and have the rep teach him.                        \n","...    ...                                                                                                        ...                        \n","2065  3034  Needed help figuring out his bill. I explained our minute charges.                                                               \n","2066  271   He lost his phone and called to cancel service. I told him we would suspend until we hear back from him. He will contact us soon.\n","2067  783   Lost the directions to phone and wants another manual. I referred him to web site.                                               \n","2068  1295  Wants to change address.                                                                                                         \n","2069  1807  He lost his phone and called to cancel service. I told him we would suspend until we hear back from him. He will contact us soon.\n","\n","[2070 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"H-Cmr8-lKGUe","colab_type":"code","outputId":"4abefca2-2fe2-476e-9cc6-4a15b65f4537","executionInfo":{"status":"ok","timestamp":1576030085121,"user_tz":420,"elapsed":1742,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":245}},"source":["#Extract target column from Customer Info file\n","y_train = CustInfoData[\"TARGET\"]\n","X_train = CustInfoData.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n","                     \n","print(X_train.shape)\n","print(textData.shape)\n","textData.head()\n","print(y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2070, 16)\n","(2070, 2)\n","0       Cancelled\n","1       Current  \n","2       Current  \n","3       Current  \n","4       Cancelled\n","          ...    \n","2065    Cancelled\n","2066    Cancelled\n","2067    Cancelled\n","2068    Cancelled\n","2069    Cancelled\n","Name: TARGET, Length: 2070, dtype: object\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A71KiKLt6veD","colab_type":"text"},"source":["# Word Tokenize"]},{"cell_type":"code","metadata":{"id":"dECrlLDRtz1O","colab_type":"code","outputId":"af280bd4-a4b3-435f-f559-dfada8a5f3d1","executionInfo":{"status":"ok","timestamp":1576030088129,"user_tz":420,"elapsed":1177,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":212}},"source":["#tokenise the sentences into words\n","textData['CommentsTokenized'] = textData['Comments'].apply(word_tokenize)\n","print(textData['CommentsTokenized'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0       [Does, not, like, the, way, the, phone, works, ., It, is, to, difficult, compared, to, his, last, phone, .]                                                       \n","1       [Wanted, to, know, the, nearest, store, location, ., Wants, to, buy, aditional, accessories, .]                                                                   \n","2       [Wants, to, know, how, to, do, text, messaging, ., Referred, him, to, website, .]                                                                                 \n","3       [Asked, how, to, disable, call, waiting, ., referred, him, to, web, site, .]                                                                                      \n","4       [Needs, help, learning, how, to, use, the, phone, ., I, suggested, he, go, back, to, the, store, and, have, the, rep, teach, him, .]                              \n","                                                                        ...                                                                                               \n","2065    [Needed, help, figuring, out, his, bill, ., I, explained, our, minute, charges, .]                                                                                \n","2066    [He, lost, his, phone, and, called, to, cancel, service, ., I, told, him, we, would, suspend, until, we, hear, back, from, him, ., He, will, contact, us, soon, .]\n","2067    [Lost, the, directions, to, phone, and, wants, another, manual, ., I, referred, him, to, web, site, .]                                                            \n","2068    [Wants, to, change, address, .]                                                                                                                                   \n","2069    [He, lost, his, phone, and, called, to, cancel, service, ., I, told, him, we, would, suspend, until, we, hear, back, from, him, ., He, will, contact, us, soon, .]\n","Name: CommentsTokenized, Length: 2070, dtype: object\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qVlY489d60QT","colab_type":"text"},"source":["# Porter Stemming"]},{"cell_type":"code","metadata":{"id":"XurC1OThzdxE","colab_type":"code","outputId":"725e8dab-9a8e-4e84-c7ce-37848c1872ab","executionInfo":{"status":"ok","timestamp":1576030109334,"user_tz":420,"elapsed":1007,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":228}},"source":["#Porter stemming\n","# Use English stemmer.\n","porter = PorterStemmer()\n","newTextData=pd.DataFrame()\n","newTextData=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n","newTextData['CommentsTokenizedStemmedPorter'] = textData['CommentsTokenized'].apply(lambda x: [porter.stem(y) for y in x])\n","print('-------------Porter Stemming------------------')\n","newTextData['CommentsTokenizedStemmedPorter']\n","#Join stemmed strings\n","newTextData['CommentsTokenizedStemmedPorter'] = newTextData['CommentsTokenizedStemmedPorter'].apply(lambda x: \" \".join(x))\n","newTextData['CommentsTokenizedStemmedPorter']"],"execution_count":0,"outputs":[{"output_type":"stream","text":["-------------Porter Stemming------------------\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0       doe not like the way the phone work . It is to difficult compar to hi last phone .                                              \n","1       want to know the nearest store locat . want to buy adit accessori .                                                             \n","2       want to know how to do text messag . refer him to websit .                                                                      \n","3       ask how to disabl call wait . refer him to web site .                                                                           \n","4       need help learn how to use the phone . I suggest he go back to the store and have the rep teach him .                           \n","                                                        ...                                                                             \n","2065    need help figur out hi bill . I explain our minut charg .                                                                       \n","2066    He lost hi phone and call to cancel servic . I told him we would suspend until we hear back from him . He will contact us soon .\n","2067    lost the direct to phone and want anoth manual . I refer him to web site .                                                      \n","2068    want to chang address .                                                                                                         \n","2069    He lost hi phone and call to cancel servic . I told him we would suspend until we hear back from him . He will contact us soon .\n","Name: CommentsTokenizedStemmedPorter, Length: 2070, dtype: object"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"jDY0AiIcJRoE","colab_type":"text"},"source":["# Creating Vector - Porter"]},{"cell_type":"code","metadata":{"id":"OxBdzDtjJMK2","colab_type":"code","outputId":"f0e5aa93-f726-4ca6-c578-fe78d65c1cfe","executionInfo":{"status":"ok","timestamp":1576030120681,"user_tz":420,"elapsed":904,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":313}},"source":["#Do Bag-Of-Words model - Term - Document Matrix - Snowball\n","#Learn the vocabulary dictionary and return term-document matrix.\n","#count_vect = CountVectorizer(stop_words=None)\n","count_vect = CountVectorizer(stop_words='english',lowercase=False)\n","count_vect\n","TD_counts = count_vect.fit_transform(newTextData.CommentsTokenizedStemmedPorter)\n","print(\"Vocabulary \",(count_vect.vocabulary_))\n","print(\"Number of words in vocabulary\",len(count_vect.vocabulary_))\n","print(\"Shape of text vector\",TD_counts.shape)\n","DF_TD_Counts=pd.DataFrame(TD_counts.toarray(), columns= count_vect.get_feature_names())\n","print(DF_TD_Counts)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Vocabulary  {'doe': 106, 'like': 181, 'way': 349, 'phone': 231, 'work': 359, 'It': 8, 'difficult': 102, 'compar': 68, 'hi': 152, 'want': 347, 'know': 175, 'nearest': 209, 'store': 293, 'locat': 186, 'buy': 47, 'adit': 18, 'accessori': 12, 'text': 312, 'messag': 199, 'refer': 254, 'websit': 352, 'ask': 31, 'disabl': 105, 'wait': 346, 'web': 351, 'site': 282, 'need': 210, 'help': 151, 'learn': 179, 'use': 340, 'suggest': 299, 'rep': 256, 'teach': 307, 'new': 212, 'plan': 233, 'switch': 306, 'soon': 287, 'minut': 201, 'addit': 15, 'access': 11, 'ori': 222, 'said': 267, 'batteri': 35, 'ha': 143, 'asap': 30, 'He': 4, 'claim': 63, 'charger': 59, 'realli': 248, 'veri': 343, 'As': 2, 'result': 259, 'wa': 345, 'alway': 22, 'die': 100, 'current': 89, 'contract': 79, 'bateri': 34, 'chang': 57, 'ring': 262, 'tone': 323, 'lost': 189, 'direct': 104, 'anoth': 26, 'manual': 196, 'number': 215, 'becaus': 36, 'mr': 206, 'napeleon': 207, 'leroy': 180, 'expect': 121, 'significantli': 278, 'better': 38, 'technic': 308, 'support': 301, 'pleas': 234, 'outbound': 224, 'list': 183, 'In': 6, 'rate': 245, 'end': 114, 'year': 364, 'inform': 166, 'famili': 126, 'screen': 270, 'facepl': 124, 'line': 182, 'week': 353, 'forward': 133, 'custom': 91, 'care': 51, 'hope': 158, 'additon': 16, 'wife': 355, 'wish': 356, 'handset': 144, 'bigger': 39, 'uncomfort': 332, 'long': 188, 'time': 318, 'unhappi': 334, 'self': 271, 'servic': 273, 'stuff': 294, 'think': 314, 'transfer': 327, 'address': 17, 'cancel': 48, 'told': 322, 'suspend': 305, 'hear': 149, 'contact': 77, 'coupl': 82, 'featur': 127, 'point': 235, 'say': 269, 'numer': 216, 'simpli': 280, 'trust': 330, 'problem': 240, 'relat': 255, 'just': 172, 'suck': 298, 'anyth': 27, 'near': 208, 'hous': 160, 'suspect': 304, 'defect': 97, 'day': 94, 'bought': 41, 'recept': 251, 'home': 157, 'horribl': 159, 'exactli': 120, 'drop': 109, 'fix': 131, 'thi': 313, 'differ': 101, 'cell': 55, 'compani': 67, 'sinc': 281, 'hate': 148, 'understand': 333, 'whi': 354, 'gave': 138, 'piec': 232, 'rubbish': 265, 'tri': 329, 'explain': 123, 'bring': 43, 'wast': 348, 'ani': 25, '3399': 0, 'car': 50, 'figur': 129, 'charg': 58, 'adress': 19, 'add': 14, 'provis': 243, 'check': 60, 'vm': 344, 'area': 29, 'manag': 194, 'xvyx': 363, 'pda': 227, 'built': 44, 'local': 185, 'function': 135, 'did': 99, 'offer': 217, 'model': 204, 'fed': 128, 'ing': 167, 'pay': 226, 'cost': 81, 'credit': 86, 'friend': 134, 'great': 141, 'signal': 277, 'weak': 350, 'replac': 257, 'simm': 279, 'chip': 61, 'wll': 357, 'reenter': 253, 'book': 40, 'make': 193, 'easier': 111, 'info': 165, 'internet': 168, 'complaint': 71, 'major': 192, 'issu': 170, 'button': 46, 'hard': 146, 'happi': 145, 'toilet': 321, 'surpris': 303, 'fine': 130, 'adapt': 13, 'perform': 229, 'send': 272, 'slow': 283, 'decent': 96, 'speed': 289, 'cstmr': 88, 'If': 5, 'consist': 75, 'consisit': 74, 'good': 140, 'transeff': 325, 'customr': 92, 'dead': 95, 'goat': 139, 'pass': 225, 'supervisor': 300, 'rude': 266, 'upset': 338, 'busi': 45, 'purpos': 244, 'useless': 341, 'cstmer': 87, 'cleariti': 64, 'bad': 32, 'static': 291, 'coverag': 84, 'lo': 184, 'angel': 23, 'york': 365, 'Is': 7, 'afraid': 21, 'network': 211, 'travel': 328, 'kid': 173, 'creat': 85, 'ticket': 316, 'dont': 108, 'kno': 174, 'someon': 285, 'wors': 360, 'abysm': 10, 'forev': 132, 'basic': 33, 'usag': 339, 'cust': 90, 'om': 219, 'locatn': 187, 'stole': 292, 'notic': 214, 'today': 320, 'dure': 110, 'tell': 309, 'polici': 236, 'lctn': 178, 'possibl': 238, 'caus': 53, 'brain': 42, 'cancer': 49, 'heard': 150, 'news': 213, 'inadequ': 163, 'everywher': 118, 'highway': 154, 'receiv': 250, 'cc': 54, 'turn': 331, 'ot': 223, 'improv': 162, 'futur': 137, '3g': 1, 'mani': 195, 'metropolitian': 200, 'terribl': 310, 'fals': 125, 'advertis': 20, 'test': 311, 'equip': 116, 'love': 191, 'hardli': 147, 'lame': 176, 'believ': 37, 'stupid': 295, 'sign': 276, 'provid': 242, 'worst': 361, 'encount': 113, 'furthermor': 136, 'shitti': 274, 'enemi': 115, 'realiz': 247, 'transf': 326, 'cold': 65, 'expir': 122, 'citi': 62, 'complain': 70, 'market': 197, 'peopl': 228, 'sold': 284, 'person': 230, 'continu': 78, 'rid': 260, 'wrong': 362, 'We': 9, 'correct': 80, 'don': 107, 'angri': 24, 'shut': 275, 'CC': 3, 'unwil': 337, 'includ': 164, 'roll': 264, 'competit': 69, 'implement': 161, 'gsm': 142, 'roam': 263, 'sale': 268, 'misl': 202, 'respect': 258, 'cover': 83, 'right': 261, 'effect': 112, 'date': 93, 'till': 317, 'hochi': 155, 'momma': 205, 'wold': 358, 'sure': 302, 'mean': 198, 'thought': 315, 'deo': 98, 'poor': 237, 'evrey': 119, 'recption': 252, 'unreli': 336, 'valu': 342, 'connect': 73, 'substant': 296, 'higher': 153, 'comapr': 66, 'option': 221, 'lot': 190, 'start': 290, 'mistak': 203, 'sometim': 286, 'properli': 241, 'constanli': 76, 'old': 218, 'everytim': 117, 'certain': 56, 'intersect': 169, 'concept': 72, 'tower': 324, 'hole': 156, 'unlimit': 335, 'reason': 249, 'anytim': 28, 'subtract': 297, 'speak': 288, 'open': 220, 'digiti': 103, 'later': 177, 'june': 171, 'probabl': 239, 'carrier': 52, 'rater': 246, 'tire': 319}\n","Number of words in vocabulary 366\n","Shape of text vector (2070, 366)\n","      3399  3g  As  CC  He  If  In  ...  work  wors  worst  wrong  xvyx  year  york\n","0     0     0   0   0   0   0   0   ...  1     0     0      0      0     0     0   \n","1     0     0   0   0   0   0   0   ...  0     0     0      0      0     0     0   \n","2     0     0   0   0   0   0   0   ...  0     0     0      0      0     0     0   \n","3     0     0   0   0   0   0   0   ...  0     0     0      0      0     0     0   \n","4     0     0   0   0   0   0   0   ...  0     0     0      0      0     0     0   \n","...  ..    ..  ..  ..  ..  ..  ..   ... ..    ..    ..     ..     ..    ..    ..   \n","2065  0     0   0   0   0   0   0   ...  0     0     0      0      0     0     0   \n","2066  0     0   0   0   2   0   0   ...  0     0     0      0      0     0     0   \n","2067  0     0   0   0   0   0   0   ...  0     0     0      0      0     0     0   \n","2068  0     0   0   0   0   0   0   ...  0     0     0      0      0     0     0   \n","2069  0     0   0   0   2   0   0   ...  0     0     0      0      0     0     0   \n","\n","[2070 rows x 366 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5weTCTU1JlBM","colab_type":"text"},"source":["# TF-IDF Matrix "]},{"cell_type":"code","metadata":{"id":"VNyELvuIJZdS","colab_type":"code","outputId":"444ebac3-5d47-4fba-a631-5f67cdf94113","executionInfo":{"status":"ok","timestamp":1576030131192,"user_tz":420,"elapsed":911,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":261}},"source":["#Compute TF-IDF Matrix\n","tfidf_transformer = TfidfTransformer()\n","X_train_tfidf = tfidf_transformer.fit_transform(DF_TD_Counts)\n","print(X_train_tfidf.shape)\n","DF_TF_IDF=pd.DataFrame(X_train_tfidf.toarray(),columns= DF_TD_Counts.columns)\n","print(DF_TF_IDF)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2070, 366)\n","      3399   3g   As   CC        He   If  ...  wors  worst  wrong  xvyx  year  york\n","0     0.0   0.0  0.0  0.0  0.000000  0.0  ...  0.0   0.0    0.0    0.0   0.0   0.0 \n","1     0.0   0.0  0.0  0.0  0.000000  0.0  ...  0.0   0.0    0.0    0.0   0.0   0.0 \n","2     0.0   0.0  0.0  0.0  0.000000  0.0  ...  0.0   0.0    0.0    0.0   0.0   0.0 \n","3     0.0   0.0  0.0  0.0  0.000000  0.0  ...  0.0   0.0    0.0    0.0   0.0   0.0 \n","4     0.0   0.0  0.0  0.0  0.000000  0.0  ...  0.0   0.0    0.0    0.0   0.0   0.0 \n","...   ...   ...  ...  ...       ...  ...  ...  ...   ...    ...    ...   ...   ... \n","2065  0.0   0.0  0.0  0.0  0.000000  0.0  ...  0.0   0.0    0.0    0.0   0.0   0.0 \n","2066  0.0   0.0  0.0  0.0  0.407251  0.0  ...  0.0   0.0    0.0    0.0   0.0   0.0 \n","2067  0.0   0.0  0.0  0.0  0.000000  0.0  ...  0.0   0.0    0.0    0.0   0.0   0.0 \n","2068  0.0   0.0  0.0  0.0  0.000000  0.0  ...  0.0   0.0    0.0    0.0   0.0   0.0 \n","2069  0.0   0.0  0.0  0.0  0.407251  0.0  ...  0.0   0.0    0.0    0.0   0.0   0.0 \n","\n","[2070 rows x 366 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g7bmx1bMKOYe","colab_type":"text"},"source":["# Feature Selection - Filter "]},{"cell_type":"code","metadata":{"id":"uqSlHN63Jo9-","colab_type":"code","outputId":"539614c9-5300-4e24-a501-65e7f73858ae","executionInfo":{"status":"ok","timestamp":1576030139604,"user_tz":420,"elapsed":508,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":765}},"source":["#Feature selection\n","selector = SelectKBest(score_func=chi2, k=30)\n","selector_fit = selector.fit(DF_TF_IDF,y_train)\n","#get scores along with features\n","names = DF_TF_IDF.columns.values[selector.get_support()]\n","scores = selector.scores_[selector.get_support()]\n","names_scores = list(zip(names, scores))\n","ns_df = pd.DataFrame(data = names_scores, columns= ['Feat_names','F_Scores'])\n","ns_df_sorted = ns_df.sort_values(['F_Scores','Feat_names'], ascending = [False, True])\n","print(ns_df_sorted)\n","\n","\n","new_DF_TF_IDF = selector.fit_transform(DF_TF_IDF,y_train)\n","print(\"Shape of TF-IDF after feature selection\", new_DF_TF_IDF.shape)\n","\n","DF_TF_IDF_SelectedFeatures= pd.DataFrame(new_DF_TF_IDF, columns = list(DF_TF_IDF.columns[selector.get_support(indices=True)]) )\n","print(DF_TF_IDF_SelectedFeatures)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["   Feat_names  F_Scores\n","19  receiv     3.660474\n","26  transeff   3.563271\n","2   alway      3.203456\n","23  screen     3.174275\n","3   cc         2.320970\n","16  ot         2.320970\n","27  turn       2.320970\n","6   continu    2.318220\n","9   figur      2.242673\n","7   explain    2.102758\n","5   charg      2.052376\n","8   famili     1.837066\n","28  unlimit    1.828956\n","13  market     1.673674\n","17  peopl      1.673674\n","22  rid        1.673674\n","25  sold       1.673674\n","10  hochi      1.556822\n","15  momma      1.556822\n","14  minut      1.496702\n","1   adress     1.446067\n","20  relat      1.437909\n","4   chang      1.414206\n","18  plan       1.379106\n","0   address    1.322337\n","24  signal     1.321208\n","29  weak       1.321208\n","12  manag      1.305570\n","11  internet   1.296248\n","21  result     1.252664\n","Shape of TF-IDF after feature selection (2070, 30)\n","       address  adress  alway   cc  ...  transeff  turn  unlimit  weak\n","0     0.000000  0.0     0.0    0.0  ...  0.0       0.0   0.0      0.0 \n","1     0.000000  0.0     0.0    0.0  ...  0.0       0.0   0.0      0.0 \n","2     0.000000  0.0     0.0    0.0  ...  0.0       0.0   0.0      0.0 \n","3     0.000000  0.0     0.0    0.0  ...  0.0       0.0   0.0      0.0 \n","4     0.000000  0.0     0.0    0.0  ...  0.0       0.0   0.0      0.0 \n","...        ...  ...     ...    ...  ...  ...       ...   ...      ... \n","2065  0.000000  0.0     0.0    0.0  ...  0.0       0.0   0.0      0.0 \n","2066  0.000000  0.0     0.0    0.0  ...  0.0       0.0   0.0      0.0 \n","2067  0.000000  0.0     0.0    0.0  ...  0.0       0.0   0.0      0.0 \n","2068  0.772949  0.0     0.0    0.0  ...  0.0       0.0   0.0      0.0 \n","2069  0.000000  0.0     0.0    0.0  ...  0.0       0.0   0.0      0.0 \n","\n","[2070 rows x 30 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eQP8cliaKpgw","colab_type":"code","outputId":"8c8eddaf-b5be-4636-a6db-c1d18d79864d","executionInfo":{"status":"ok","timestamp":1576030145500,"user_tz":420,"elapsed":942,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":66}},"source":["#split data into training and test\n","#split the entire training data in training and test data\n","X_Train, X_Test, Y_Train, Y_Test = train_test_split( DF_TF_IDF_SelectedFeatures, y_train, test_size=0.20, random_state=42)\n","print(\"Initial shape for entire data:\",DF_TF_IDF_SelectedFeatures.shape)\n","print(\"Shape of new training data:\", X_Train.shape)\n","print(\"Shape of new test split data:\", X_Test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Initial shape for entire data: (2070, 30)\n","Shape of new training data: (1656, 30)\n","Shape of new test split data: (414, 30)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-lQw4QrlK4EO","colab_type":"text"},"source":["# Classification model on only comments - Random Forest - Filter"]},{"cell_type":"code","metadata":{"id":"to-WwTSdK2q-","colab_type":"code","outputId":"c710a25c-809e-48de-9cb0-7929d31baed5","executionInfo":{"status":"ok","timestamp":1576030155189,"user_tz":420,"elapsed":1161,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":423}},"source":["#Construct a Random Forest Classifier on text data\n","rfc=RandomForestClassifier()\n","rfc.fit(X_Train,Y_Train)\n","\n","#Prediction on training data\n","pred_rf=pd.DataFrame(rfc.predict(X_Train),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Training Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on training data using Random Forest:\",accuracy_score(Y_Train,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on training data using Random Forest\\n\", confusion_matrix(Y_Train,pred_rf[\"Prediction\"]))\n","\n","# prediction on test data\n","pred_rf=pd.DataFrame(rfc.predict(X_Test),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Test Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on test data using Random Forest:\",accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Balanced Accuracy Score on test data using Random Forest:\",balanced_accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on test data using Random Forest\\n\", confusion_matrix(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Classification report on test data using Random Forest\\n\", classification_report(Y_Test,pred_rf[\"Prediction\"]))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["----------------------------Random Forest: Training Data------------------------------------------------\n","\n","Accuracy Score on training data using Random Forest: 0.6268115942028986\n","Confusion Matrix on training data using Random Forest\n"," [[ 63 584]\n"," [ 34 975]]\n","----------------------------Random Forest: Test Data------------------------------------------------\n","\n","Accuracy Score on test data using Random Forest: 0.6207729468599034\n","Balanced Accuracy Score on test data using Random Forest: 0.5148702570076087\n","Confusion Matrix on test data using Random Forest\n"," [[ 12 145]\n"," [ 12 245]]\n","Classification report on test data using Random Forest\n","               precision    recall  f1-score   support\n","\n","   Cancelled       0.50      0.08      0.13       157\n","     Current       0.63      0.95      0.76       257\n","\n","    accuracy                           0.62       414\n","   macro avg       0.56      0.51      0.44       414\n","weighted avg       0.58      0.62      0.52       414\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"6o0Izqz5LZC6","colab_type":"text"},"source":["#customer data "]},{"cell_type":"code","metadata":{"id":"wrFT9ohILWj4","colab_type":"code","outputId":"3e27d6d2-ec8f-48de-816e-4e0719d322a5","executionInfo":{"status":"ok","timestamp":1576030164718,"user_tz":420,"elapsed":1046,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":147}},"source":["CustInfoData = CustInfoData.drop(columns=[\"TARGET\"])\n","#Do one Hot encoding for categorical features\n","X_cat = [\"Sex\",\"Status\",\"Car_Owner\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\"]\n","#X_cat = CustInfoData.select_dtypes(include=['object'])\n","customer_one_hot = pd.get_dummies(CustInfoData,columns=X_cat)\n","\n","customer_one_hot = pd.DataFrame(customer_one_hot)\n","print(customer_one_hot.head())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["   ID  ...  LongDistanceBilltype_Standard\n","0  1   ...  0                            \n","1  6   ...  1                            \n","2  8   ...  1                            \n","3  11  ...  1                            \n","4  14  ...  0                            \n","\n","[5 rows x 24 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lNBqoN4XL3lx","colab_type":"text"},"source":["# Classification model on comments + customer data - Random Forest - Filter"]},{"cell_type":"code","metadata":{"id":"23asu6JWL8hA","colab_type":"code","outputId":"3b1185fd-9d6a-4f69-de20-324642149c15","executionInfo":{"status":"ok","timestamp":1576030188500,"user_tz":420,"elapsed":969,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":261}},"source":["#Merge files comments and customer data\n","combined=pd.concat([customer_one_hot, DF_TF_IDF_SelectedFeatures], axis=1)\n","print(combined.shape)\n","print(combined)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2070, 54)\n","        ID  Children  Est_Income   Usage  ...  transeff  turn  unlimit  weak\n","0     1     1         38000.00    229.64  ...  0.0       0.0   0.0      0.0 \n","1     6     2         29616.00    75.29   ...  0.0       0.0   0.0      0.0 \n","2     8     0         19732.80    47.25   ...  0.0       0.0   0.0      0.0 \n","3     11    2         96.33       59.01   ...  0.0       0.0   0.0      0.0 \n","4     14    2         52004.80    28.14   ...  0.0       0.0   0.0      0.0 \n","...   ..   ..              ...      ...   ...  ...       ...   ...      ... \n","2065  3821  0         78851.30    29.04   ...  0.0       0.0   0.0      0.0 \n","2066  3822  1         17540.70    36.20   ...  0.0       0.0   0.0      0.0 \n","2067  3823  0         83891.90    74.40   ...  0.0       0.0   0.0      0.0 \n","2068  3824  2         28220.80    38.95   ...  0.0       0.0   0.0      0.0 \n","2069  3825  0         28589.10    100.28  ...  0.0       0.0   0.0      0.0 \n","\n","[2070 rows x 54 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_EdxKKPaMNqV","colab_type":"code","outputId":"c014218b-9952-44d8-a544-18b84ffc56e9","executionInfo":{"status":"ok","timestamp":1576030191513,"user_tz":420,"elapsed":736,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":66}},"source":["#split data into training and test\n","#split the entire training data in training and test data\n","X_Train, X_Test, Y_Train, Y_Test = train_test_split( combined, y_train, test_size=0.20, random_state=42)\n","print(\"Initial shape for entire data:\",DF_TF_IDF_SelectedFeatures.shape)\n","print(\"Shape of new training data:\", X_Train.shape)\n","print(\"Shape of new test split data:\", X_Test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Initial shape for entire data: (2070, 30)\n","Shape of new training data: (1656, 54)\n","Shape of new test split data: (414, 54)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X_gf4Xm2MZjs","colab_type":"code","outputId":"0011b683-c28c-4d00-d1bc-a0f2ee233a5b","executionInfo":{"status":"ok","timestamp":1576030194247,"user_tz":420,"elapsed":1132,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":423}},"source":["#Construct a Random Forest Classifier on combined data\n","rfc=RandomForestClassifier()\n","rfc.fit(X_Train,Y_Train)\n","\n","#Prediction on training data\n","pred_rf=pd.DataFrame(rfc.predict(X_Train),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Training Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on training data using Random Forest:\",accuracy_score(Y_Train,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on training data using Random Forest\\n\", confusion_matrix(Y_Train,pred_rf[\"Prediction\"]))\n","\n","# prediction on test data\n","pred_rf=pd.DataFrame(rfc.predict(X_Test),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Test Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on test data using Random Forest:\",accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Balanced Accuracy Score on test data using Random Forest:\",balanced_accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on test data using Random Forest\\n\", confusion_matrix(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Classification report on test data using Random Forest\\n\", classification_report(Y_Test,pred_rf[\"Prediction\"]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["----------------------------Random Forest: Training Data------------------------------------------------\n","\n","Accuracy Score on training data using Random Forest: 0.9903381642512077\n","Confusion Matrix on training data using Random Forest\n"," [[645   2]\n"," [ 14 995]]\n","----------------------------Random Forest: Test Data------------------------------------------------\n","\n","Accuracy Score on test data using Random Forest: 0.8671497584541062\n","Balanced Accuracy Score on test data using Random Forest: 0.8607772187662643\n","Confusion Matrix on test data using Random Forest\n"," [[131  26]\n"," [ 29 228]]\n","Classification report on test data using Random Forest\n","               precision    recall  f1-score   support\n","\n","   Cancelled       0.82      0.83      0.83       157\n","     Current       0.90      0.89      0.89       257\n","\n","    accuracy                           0.87       414\n","   macro avg       0.86      0.86      0.86       414\n","weighted avg       0.87      0.87      0.87       414\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"mprsVNwgMmGE","colab_type":"text"},"source":["# Feature selection - Wrapper method "]},{"cell_type":"code","metadata":{"id":"VVr9XX-ZMlOr","colab_type":"code","outputId":"5df317ba-3719-4780-b1fa-7ba804d475a3","executionInfo":{"status":"ok","timestamp":1576030401607,"user_tz":420,"elapsed":196558,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n","#Construct a Random Forest Classifier on text data\n","rfc=RandomForestClassifier()\n","\n","sfs1 = SFS(rfc, \n","           k_features=20, \n","           forward=True, \n","           floating=False, \n","           verbose=2,\n","           scoring='accuracy',\n","           cv=0)\n","\n","sfs1 = sfs1.fit(DF_TF_IDF,y_train, custom_feature_names= DF_TF_IDF.columns)\n","print(\"Top 20 feature\", sfs1.k_feature_names_)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=DeprecationWarning)\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 366 out of 366 | elapsed:    7.6s finished\n","\n","[2019-12-11 02:10:13] Features: 1/20 -- score: 0.6246376811594203[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 365 out of 365 | elapsed:    8.5s finished\n","\n","[2019-12-11 02:10:21] Features: 2/20 -- score: 0.6304347826086957[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 364 out of 364 | elapsed:    9.2s finished\n","\n","[2019-12-11 02:10:30] Features: 3/20 -- score: 0.6318840579710145[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 363 out of 363 | elapsed:    9.4s finished\n","\n","[2019-12-11 02:10:40] Features: 4/20 -- score: 0.633816425120773[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 362 out of 362 | elapsed:    9.6s finished\n","\n","[2019-12-11 02:10:49] Features: 5/20 -- score: 0.6347826086956522[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 361 out of 361 | elapsed:    9.6s finished\n","\n","[2019-12-11 02:10:59] Features: 6/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:    9.6s finished\n","\n","[2019-12-11 02:11:09] Features: 7/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 359 out of 359 | elapsed:    9.6s finished\n","\n","[2019-12-11 02:11:18] Features: 8/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 358 out of 358 | elapsed:   10.0s finished\n","\n","[2019-12-11 02:11:28] Features: 9/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 357 out of 357 | elapsed:   10.0s finished\n","\n","[2019-12-11 02:11:38] Features: 10/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 356 out of 356 | elapsed:   10.0s finished\n","\n","[2019-12-11 02:11:48] Features: 11/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 355 out of 355 | elapsed:   10.0s finished\n","\n","[2019-12-11 02:11:58] Features: 12/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 354 out of 354 | elapsed:   10.0s finished\n","\n","[2019-12-11 02:12:08] Features: 13/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 353 out of 353 | elapsed:   10.0s finished\n","\n","[2019-12-11 02:12:18] Features: 14/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 352 out of 352 | elapsed:   10.1s finished\n","\n","[2019-12-11 02:12:28] Features: 15/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 351 out of 351 | elapsed:   10.5s finished\n","\n","[2019-12-11 02:12:39] Features: 16/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 350 out of 350 | elapsed:   10.5s finished\n","\n","[2019-12-11 02:12:49] Features: 17/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 349 out of 349 | elapsed:   10.5s finished\n","\n","[2019-12-11 02:13:00] Features: 18/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 348 out of 348 | elapsed:   10.5s finished\n","\n","[2019-12-11 02:13:10] Features: 19/20 -- score: 0.6352657004830918[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["Top 20 feature ('3399', '3g', 'As', 'He', 'In', 'Is', 'We', 'abysm', 'accessori', 'add', 'addit', 'additon', 'adress', 'afraid', 'alway', 'hi', 'hochi', 'support', 'want', 'work')\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done 347 out of 347 | elapsed:   10.5s finished\n","\n","[2019-12-11 02:13:21] Features: 20/20 -- score: 0.6352657004830918"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"C55JGKvjbTYo","colab_type":"code","outputId":"66efbd43-5c7e-49f5-86a7-92d3be6c978d","executionInfo":{"status":"ok","timestamp":1576030401618,"user_tz":420,"elapsed":191332,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":297}},"source":["#top 20 features after Forward\n","print(\"Top 20 feature\", sfs1.k_feature_names_)\n","\n","DF_TF_IDF_SelectedFeatures = DF_TF_IDF.loc[:, DF_TF_IDF.columns.isin(list(sfs1.k_feature_names_))]\n","print(\"Shape of TF-IDF after feature selection\", DF_TF_IDF_SelectedFeatures.shape)\n","print(DF_TF_IDF_SelectedFeatures)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Top 20 feature ('3399', '3g', 'As', 'He', 'In', 'Is', 'We', 'abysm', 'accessori', 'add', 'addit', 'additon', 'adress', 'afraid', 'alway', 'hi', 'hochi', 'support', 'want', 'work')\n","Shape of TF-IDF after feature selection (2070, 20)\n","      3399   3g   As        He  ...  hochi  support      want      work\n","0     0.0   0.0  0.0  0.000000  ...  0.0    0.0      0.000000  0.192632\n","1     0.0   0.0  0.0  0.000000  ...  0.0    0.0      0.312065  0.000000\n","2     0.0   0.0  0.0  0.000000  ...  0.0    0.0      0.195324  0.000000\n","3     0.0   0.0  0.0  0.000000  ...  0.0    0.0      0.000000  0.000000\n","4     0.0   0.0  0.0  0.000000  ...  0.0    0.0      0.000000  0.000000\n","...   ...   ...  ...       ...  ...  ...    ...           ...       ...\n","2065  0.0   0.0  0.0  0.000000  ...  0.0    0.0      0.000000  0.000000\n","2066  0.0   0.0  0.0  0.407251  ...  0.0    0.0      0.000000  0.000000\n","2067  0.0   0.0  0.0  0.000000  ...  0.0    0.0      0.144882  0.000000\n","2068  0.0   0.0  0.0  0.000000  ...  0.0    0.0      0.324251  0.000000\n","2069  0.0   0.0  0.0  0.407251  ...  0.0    0.0      0.000000  0.000000\n","\n","[2070 rows x 20 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vf39k9h9qFDv","colab_type":"code","outputId":"a1dd3647-cb6f-4bd4-d3dd-199d11ef6eeb","executionInfo":{"status":"ok","timestamp":1576030401619,"user_tz":420,"elapsed":188779,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":66}},"source":["#split data into training and test\n","#split the entire training data in training and test data\n","X_Train, X_Test, Y_Train, Y_Test = train_test_split( DF_TF_IDF_SelectedFeatures, y_train, test_size=0.20, random_state=42)\n","print(\"Initial shape for entire data:\",DF_TF_IDF_SelectedFeatures.shape)\n","print(\"Shape of new training data:\", X_Train.shape)\n","print(\"Shape of new test split data:\", X_Test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Initial shape for entire data: (2070, 20)\n","Shape of new training data: (1656, 20)\n","Shape of new test split data: (414, 20)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xf3YiRRaq66H","colab_type":"text"},"source":["# Classification on comments - Wrapper method"]},{"cell_type":"code","metadata":{"id":"KyZbFD2_jml7","colab_type":"code","outputId":"eb071c79-4709-48ae-afe4-367452d3d8c1","executionInfo":{"status":"ok","timestamp":1576030401621,"user_tz":420,"elapsed":183318,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":423}},"source":["#Construct a Random Forest Classifier on text data\n","rfc=RandomForestClassifier()\n","rfc.fit(X_Train,Y_Train)\n","\n","#Prediction on training data\n","pred_rf=pd.DataFrame(rfc.predict(X_Train),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Training Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on training data using Random Forest:\",accuracy_score(Y_Train,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on training data using Random Forest\\n\", confusion_matrix(Y_Train,pred_rf[\"Prediction\"]))\n","\n","# prediction on test data\n","pred_rf=pd.DataFrame(rfc.predict(X_Test),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Test Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on test data using Random Forest:\",accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Balanced Accuracy Score on test data using Random Forest:\",balanced_accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on test data using Random Forest\\n\", confusion_matrix(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Classification report on test data using Random Forest\\n\", classification_report(Y_Test,pred_rf[\"Prediction\"]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["----------------------------Random Forest: Training Data------------------------------------------------\n","\n","Accuracy Score on training data using Random Forest: 0.6346618357487923\n","Confusion Matrix on training data using Random Forest\n"," [[ 82 565]\n"," [ 40 969]]\n","----------------------------Random Forest: Test Data------------------------------------------------\n","\n","Accuracy Score on test data using Random Forest: 0.606280193236715\n","Balanced Accuracy Score on test data using Random Forest: 0.4994795410047337\n","Confusion Matrix on test data using Random Forest\n"," [[  9 148]\n"," [ 15 242]]\n","Classification report on test data using Random Forest\n","               precision    recall  f1-score   support\n","\n","   Cancelled       0.38      0.06      0.10       157\n","     Current       0.62      0.94      0.75       257\n","\n","    accuracy                           0.61       414\n","   macro avg       0.50      0.50      0.42       414\n","weighted avg       0.53      0.61      0.50       414\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Y4SZS-MtrVJm","colab_type":"text"},"source":["# Classification on customers + comments - Wrapper method"]},{"cell_type":"code","metadata":{"id":"zOKJ_1jPrKnq","colab_type":"code","outputId":"56c1c705-767e-4ef1-cad2-7e15b5713937","executionInfo":{"status":"ok","timestamp":1576030401622,"user_tz":420,"elapsed":180730,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":261}},"source":["#Merge files comments and customer data\n","combined=pd.concat([customer_one_hot, DF_TF_IDF_SelectedFeatures], axis=1)\n","print(combined.shape)\n","print(combined)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2070, 44)\n","        ID  Children  Est_Income   Usage  ...  hochi  support      want      work\n","0     1     1         38000.00    229.64  ...  0.0    0.0      0.000000  0.192632\n","1     6     2         29616.00    75.29   ...  0.0    0.0      0.312065  0.000000\n","2     8     0         19732.80    47.25   ...  0.0    0.0      0.195324  0.000000\n","3     11    2         96.33       59.01   ...  0.0    0.0      0.000000  0.000000\n","4     14    2         52004.80    28.14   ...  0.0    0.0      0.000000  0.000000\n","...   ..   ..              ...      ...   ...  ...    ...           ...       ...\n","2065  3821  0         78851.30    29.04   ...  0.0    0.0      0.000000  0.000000\n","2066  3822  1         17540.70    36.20   ...  0.0    0.0      0.000000  0.000000\n","2067  3823  0         83891.90    74.40   ...  0.0    0.0      0.144882  0.000000\n","2068  3824  2         28220.80    38.95   ...  0.0    0.0      0.324251  0.000000\n","2069  3825  0         28589.10    100.28  ...  0.0    0.0      0.000000  0.000000\n","\n","[2070 rows x 44 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ABNqBUMrrxdn","colab_type":"code","outputId":"44eda12d-b0a1-48bd-8e08-df45bb663505","executionInfo":{"status":"ok","timestamp":1576030401913,"user_tz":420,"elapsed":179087,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":66}},"source":["#split data into training and test\n","#split the entire training data in training and test data\n","X_Train, X_Test, Y_Train, Y_Test = train_test_split( combined, y_train, test_size=0.20, random_state=42)\n","print(\"Initial shape for entire data:\",DF_TF_IDF_SelectedFeatures.shape)\n","print(\"Shape of new training data:\", X_Train.shape)\n","print(\"Shape of new test split data:\", X_Test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Initial shape for entire data: (2070, 20)\n","Shape of new training data: (1656, 44)\n","Shape of new test split data: (414, 44)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RdJwKIYWryF9","colab_type":"code","outputId":"4a49bd55-ed0e-4e6f-ac0a-8ddfe03e7a6f","executionInfo":{"status":"ok","timestamp":1576030402158,"user_tz":420,"elapsed":485,"user":{"displayName":"Seerat Chhabra","photoUrl":"","userId":"10179864280199177168"}},"colab":{"base_uri":"https://localhost:8080/","height":423}},"source":["#Construct a Random Forest Classifier on combined data\n","rfc=RandomForestClassifier()\n","rfc.fit(X_Train,Y_Train)\n","\n","#Prediction on training data\n","pred_rf=pd.DataFrame(rfc.predict(X_Train),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Training Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on training data using Random Forest:\",accuracy_score(Y_Train,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on training data using Random Forest\\n\", confusion_matrix(Y_Train,pred_rf[\"Prediction\"]))\n","\n","# prediction on test data\n","pred_rf=pd.DataFrame(rfc.predict(X_Test),columns=[\"Prediction\"])\n","print(\"----------------------------Random Forest: Test Data------------------------------------------------\\n\")\n","print(\"Accuracy Score on test data using Random Forest:\",accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Balanced Accuracy Score on test data using Random Forest:\",balanced_accuracy_score(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Confusion Matrix on test data using Random Forest\\n\", confusion_matrix(Y_Test,pred_rf[\"Prediction\"]))\n","print(\"Classification report on test data using Random Forest\\n\", classification_report(Y_Test,pred_rf[\"Prediction\"]))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["----------------------------Random Forest: Training Data------------------------------------------------\n","\n","Accuracy Score on training data using Random Forest: 0.9903381642512077\n","Confusion Matrix on training data using Random Forest\n"," [[643   4]\n"," [ 12 997]]\n","----------------------------Random Forest: Test Data------------------------------------------------\n","\n","Accuracy Score on test data using Random Forest: 0.855072463768116\n","Balanced Accuracy Score on test data using Random Forest: 0.8448536518872835\n","Confusion Matrix on test data using Random Forest\n"," [[126  31]\n"," [ 29 228]]\n","Classification report on test data using Random Forest\n","               precision    recall  f1-score   support\n","\n","   Cancelled       0.81      0.80      0.81       157\n","     Current       0.88      0.89      0.88       257\n","\n","    accuracy                           0.86       414\n","   macro avg       0.85      0.84      0.85       414\n","weighted avg       0.85      0.86      0.85       414\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"],"name":"stderr"}]}]}